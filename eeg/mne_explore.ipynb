{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuous-swift",
   "metadata": {},
   "source": [
    "# Exploring MNE-Python library for EEG analysis\n",
    "Practice MNE-Python and the eeg processing pipeline for 1 session data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-condition",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mne.preprocessing import ICA\n",
    "from matplotlib import rcParams\n",
    "import xml.etree.cElementTree as et\n",
    "\n",
    "# figure size in inches: \n",
    "# https://stackoverflow.com/questions/31594549/\n",
    "# how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "rcParams['figure.figsize'] = 11.7,8.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the data manual\n",
    "EEG_CHANNELS = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', \n",
    "                'CP1', 'P3', 'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', \n",
    "                'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6', \n",
    "                'CP2', 'P4', 'P8', 'PO4', 'O2']\n",
    "STIM_CHANNELS = ['Status']\n",
    "OTHER_CHANNELS = ['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', \n",
    "                  'EXG8', 'GSR1', 'GSR2', 'Erg1', 'Erg2', 'Resp', 'Temp']\n",
    "\n",
    "# Taken from https://github.com/TNEL-UCSD/limbic-analysis-dynamics/blob/\n",
    "#            master/scripts/iads_gen_features.py\n",
    "FREQ_RANGES = {\n",
    "    'delta': [2., 3.5],\n",
    "    'theta': [4., 7.],\n",
    "    'alpha': [9., 11.],\n",
    "    'beta': [15., 30.],\n",
    "    'gamma': [35., 55.],\n",
    "    'high_gamma': [90., 110.]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/net2/expData/affective_eeg/mahnob_dataset/Sessions\"\n",
    "session_path = \"10\"\n",
    "meta_data_path = \"session.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-advantage",
   "metadata": {},
   "source": [
    "Read in raw data. Notebook tested with data from Session 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = os.path.join(dataset_path, session_path, \"Part_1_S_Trial5_emotion.bdf\")\n",
    "\n",
    "raw = mne.io.read_raw_bdf(raw_path)\n",
    "raw.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-checkout",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-baker",
   "metadata": {},
   "source": [
    "#### Drop channel and rereference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra channels based on manual\n",
    "data_dropch = raw.copy().drop_channels(OTHER_CHANNELS)\n",
    "\n",
    "# Rereference data. \n",
    "# See https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html\n",
    "#     #biosemi-data-format-bdf\n",
    "data_reref, ref_data = mne.set_eeg_reference(data_dropch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-kazakhstan",
   "metadata": {},
   "source": [
    "#### Find events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.copy().pick_types(eeg=False, stim=True).plot(duration=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel=\"Status\")\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-rebel",
   "metadata": {},
   "source": [
    "Stimuli start and stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-stuff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data_reref)\n",
    "print(data_reref.info)\n",
    "print(data_reref.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.info[\"sfreq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-symposium",
   "metadata": {},
   "source": [
    "#### Sensor map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.set_montage('standard_1020')\n",
    "data_reref.plot_sensors(show_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-being",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.plot(duration=10, n_channels=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.plot_psd()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.plot_psd(fmin=45, fmax=55)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt = data_reref.copy().filter(l_freq=1, h_freq=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reref.plot(duration=160, n_channels=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt.plot(duration=160, n_channels=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt.plot(duration=10, n_channels=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-appreciation",
   "metadata": {},
   "source": [
    "#### ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = ICA(n_components=15, max_iter=1000, random_state=413)\n",
    "ica.fit(data_filt)\n",
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(data_filt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-percentage",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ica.plot_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-jordan",
   "metadata": {},
   "source": [
    "Project back to channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [0, 1]\n",
    "data_ica = data_filt.copy()\n",
    "ica.apply(data_ica)\n",
    "\n",
    "data_filt.plot(show_scrollbars=False)\n",
    "data_ica.plot(show_scrollbars=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-console",
   "metadata": {},
   "source": [
    "#### Cut out Stimuli presentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot find method of conversion. Use time index / sampling frequency\n",
    "event_indexes = [events[x][0] for x in range(len(events))]\n",
    "sampling_freq = int(data_ica.info[\"sfreq\"])\n",
    "event_times = [int(index / sampling_freq) for index in event_indexes]\n",
    "\n",
    "data_cropped = data_ica.copy().drop_channels(STIM_CHANNELS)\n",
    "data_cropped.crop(tmin=event_times[0], tmax=event_times[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cropped.plot(duration=105, n_channels=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_cropped.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-dover",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-founder",
   "metadata": {},
   "source": [
    "For a relatively small number of features, we let:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freq_bands = 2\n",
    "num_channels = 5\n",
    "duration = int(len(data_cropped) / sampling_freq)\n",
    "num_sample = int(duration / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-adapter",
   "metadata": {},
   "source": [
    "For actual model comparision, probably need multiple feature extractions with different channels and frequency bands used.\n",
    "\n",
    "For now, stick to a set group of frequency bands and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = [\"alpha\", \"beta\"]\n",
    "channels = [\"F3\", \"Fz\", \"F4\", \"FC1\", \"FC2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-manner",
   "metadata": {},
   "source": [
    "#### Make Frequency band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used = data_cropped.copy().pick_channels(ch_names=channels)\n",
    "\n",
    "list_data_by_freq = []\n",
    "for i in range(len(freq_bands)):\n",
    "    list_data_by_freq.append(\n",
    "        data_used.copy().filter(\n",
    "            l_freq=FREQ_RANGES[freq_bands[i]][0], \n",
    "            h_freq=FREQ_RANGES[freq_bands[i]][1]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-charity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list_data_by_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_by_freq[0].plot(duration=105)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_by_freq[1].plot(duration=105)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-recorder",
   "metadata": {},
   "source": [
    "#### Z-score data & Hilbert transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from limbic-analysis-dynamics feature extraction scripts\n",
    "# See https://github.com/TNEL-UCSD/limbic-analysis-dynamics/blob/master/\n",
    "#     scripts/iads_gen_features.py\n",
    "for data in list_data_by_freq:\n",
    "    data_hilbert = data.get_data()\n",
    "    # mean across time per channel\n",
    "    m = np.mean(data_hilbert, axis=1)\n",
    "    m = np.tile(m,(data_hilbert.shape[1],1)).T\n",
    "    s = np.std(data_hilbert, axis=1, ddof=1)\n",
    "    s = np.tile(s, (data_hilbert.shape[1],1)).T\n",
    "    z_score = (data_hilbert - m) / s\n",
    "\n",
    "    data.apply_function(lambda _: z_score, channel_wise=False)\n",
    "    data.apply_hilbert(n_jobs=16, envelope=True)\n",
    "    data.apply_function(np.square, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = pd.DataFrame(list_data_by_freq[0].get_data().T, columns=channels)\n",
    "beta = pd.DataFrame(list_data_by_freq[1].get_data().T, columns=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-recipe",
   "metadata": {},
   "source": [
    "#### Resampling & making feature array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lose some data at the end of the recording. < 30/256 = 0.12s\n",
    "num_index = len(alpha[\"FC1\"])\n",
    "idx_per_sample = int(num_index / num_sample)\n",
    "sample_seps = [x * idx_per_sample for x in range(num_sample + 1)]\n",
    "\n",
    "print(\"Number of samples:\", num_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_array = np.array(alpha.T)\n",
    "beta_array = np.array(beta.T)\n",
    "\n",
    "features = []\n",
    "for a_ch, b_ch in zip(alpha_array, beta_array):\n",
    "    channel = []\n",
    "    \n",
    "    for i in range(len(sample_seps) - 1):\n",
    "        start = sample_seps[i]\n",
    "        end = sample_seps[i+1]\n",
    "        \n",
    "        alpha_sample = np.mean(a_ch[start:end])\n",
    "        beta_sample = np.mean(b_ch[start:end])\n",
    "        \n",
    "        channel.append(alpha_sample)\n",
    "        channel.append(beta_sample)\n",
    "        \n",
    "    features.append(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-handling",
   "metadata": {},
   "source": [
    "__!!! Note: The above code make all alpha band samples have odd index in the feature array, and even indexes for beta band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-gnome",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Make 1D array (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-nelson",
   "metadata": {},
   "source": [
    "## Extract Affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = os.path.join(dataset_path, session_path, meta_data_path)\n",
    "tree = et.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "va_results = [valence, arousal] = [int(root.attrib[\"feltVlnc\"]), \n",
    "                                   int(root.attrib[\"feltArsl\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-saturday",
   "metadata": {},
   "source": [
    "Following Siddarth study, classify into 4 category: \"low valence low arousal\", \"low valence high arousal\", \"high valence low arousal\", and \"high valence high arousal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5\n",
    "categories = {\n",
    "    \"lvla\": 0,\n",
    "    \"lvha\": 1,\n",
    "    \"hvla\": 2,\n",
    "    \"hvha\": 3\n",
    "}\n",
    "\n",
    "result = -1\n",
    "\n",
    "if (valence <= cutoff) and (arousal <= cutoff):\n",
    "    result = 0\n",
    "elif (valence <= cutoff) and (arousal > cutoff):\n",
    "    result = 1\n",
    "elif (valence > cutoff) and (arousal <= cutoff):\n",
    "    result = 2\n",
    "else:\n",
    "    result = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-america",
   "metadata": {},
   "source": [
    "#### Prediction based on features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-brooklyn",
   "metadata": {},
   "source": [
    "Use LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-angel",
   "metadata": {},
   "source": [
    "Use scikit-learn for LDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
